{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBOlFYpnlr0N"
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "PM5EnXhLk6BL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vgAdz_b8xp8w",
    "outputId": "14cd6ea6-4a61-4b22-f2a6-59088a78e58a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/muratdogan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#@title Turkish StopWords\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "turkish_stopwords = stopwords.words('turkish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plt9-VkNmlmH"
   },
   "source": [
    "# Influencer Category Classification\n",
    "\n",
    "\n",
    "\n",
    "1.   Read Data\n",
    "2.   Preprocess Data\n",
    "3.   Prepare Model\n",
    "4.   Predict Test Data\n",
    "4.   Save outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "8DeBh-b7lrEs"
   },
   "outputs": [],
   "source": [
    "train_classification_df = pd.read_csv(\"train-classification.csv\",)\n",
    "train_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})\n",
    "\n",
    "# Unifying labels\n",
    "train_classification_df[\"category\"] = train_classification_df[\"category\"].apply(str.lower)\n",
    "username2_category = train_classification_df.set_index(\"user_id\").to_dict()[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "SfD7BQ3hE5Jh",
    "outputId": "a67f08dd-ab3e-491f-bfe2-a14da0e961cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fashion</th>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaming</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health and lifestyle</th>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom and children</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>travel</th>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_id\n",
       "category                     \n",
       "art                       191\n",
       "entertainment             323\n",
       "fashion                   299\n",
       "food                      511\n",
       "gaming                     13\n",
       "health and lifestyle      503\n",
       "mom and children          149\n",
       "sports                    113\n",
       "tech                      346\n",
       "travel                    294"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stats about the labels\n",
    "train_classification_df.groupby(\"category\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "GT_IcUM2nGBH"
   },
   "outputs": [],
   "source": [
    "train_data_path = \"training-dataset.jsonl.gz\"\n",
    "\n",
    "username2posts_train = dict()\n",
    "username2profile_train = dict()\n",
    "\n",
    "username2posts_test = dict()\n",
    "username2profile_test = dict()\n",
    "\n",
    "\n",
    "with gzip.open(train_data_path, \"rt\") as fh:\n",
    "  for line in fh:\n",
    "    sample = json.loads(line)\n",
    "\n",
    "    profile = sample[\"profile\"]\n",
    "    username = profile[\"username\"]\n",
    "    if username in username2_category:\n",
    "      # train data info\n",
    "      username2posts_train[username] = sample[\"posts\"]\n",
    "      username2profile_train[username] = profile\n",
    "\n",
    "\n",
    "    else:\n",
    "      # it is test data info\n",
    "      username2posts_test[username] = sample[\"posts\"]\n",
    "      username2profile_test[username] = profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "djeF1GQ1oy3v",
    "outputId": "5c2ead24-d7d1-4df8-bec0-bf2152c76832"
   },
   "outputs": [],
   "source": [
    "train_profile_df = pd.DataFrame(username2profile_train).T.reset_index(drop=True)\n",
    "test_profile_df = pd.DataFrame(username2profile_test).T.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Z5UY0eYLsoTr"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "def preprocess_text(text: str):\n",
    "    # lower casing Turkish Text, Don't use str.lower :)\n",
    "    text = text.casefold()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    # HERE THE EMOJIS stuff are being removed, you may want to keep them :D\n",
    "    text = re.sub(r'[^a-zçğıöşü0-9\\s#@]', '', text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "corpus = []\n",
    "\n",
    "# to keep the label order\n",
    "train_usernames = []\n",
    "\n",
    "for username, posts in username2posts_train.items():\n",
    "  train_usernames.append(username)\n",
    "\n",
    "  # aggregating the posts per user\n",
    "  cleaned_captions = []\n",
    "  for post in posts:\n",
    "    post_caption = post.get(\"caption\", \"\")\n",
    "    if post_caption is None:\n",
    "      continue\n",
    "\n",
    "    post_caption = preprocess_text(post_caption)\n",
    "\n",
    "    if post_caption != \"\":\n",
    "      cleaned_captions.append(post_caption)\n",
    "\n",
    "\n",
    "  # joining the posts of each user with a \\n\n",
    "  user_post_captions = \"\\n\".join(cleaned_captions)\n",
    "  corpus.append(user_post_captions)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=turkish_stopwords, max_features=5000)\n",
    "\n",
    "# fit the vectorizer\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "\n",
    "# transform the data into vectors\n",
    "x_post_train = vectorizer.transform(corpus)\n",
    "y_train = [username2_category.get(uname, \"NA\") for uname in train_usernames]\n",
    "\n",
    "\n",
    "test_usernames = []\n",
    "test_corpus = []\n",
    "for username, posts in username2posts_test.items():\n",
    "  test_usernames.append(username)\n",
    "  # aggregating the posts per user\n",
    "  cleaned_captions = []\n",
    "  for post in posts:\n",
    "    post_caption = post.get(\"caption\", \"\")\n",
    "    if post_caption is None:\n",
    "      continue\n",
    "\n",
    "    post_caption = preprocess_text(post_caption)\n",
    "\n",
    "    if post_caption != \"\":\n",
    "      cleaned_captions.append(post_caption)\n",
    "\n",
    "  user_post_captions = \"\\n\".join(cleaned_captions)\n",
    "  test_corpus.append(user_post_captions)\n",
    "\n",
    "\n",
    "# Just transforming! No Fitting!!!!!\n",
    "x_post_test = vectorizer.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Q-BcPjw_39aP"
   },
   "outputs": [],
   "source": [
    "assert y_train.count(\"NA\") == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XP9ZrOIAvi9z",
    "outputId": "47634b8e-f5d0-4160-aab4-2cc60b4900e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abdullah', 'abone', 'about', ..., 'şık', 'şıklık', 'şıklığı'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "xa4v453o0Mo_",
    "outputId": "4787ecd7-ba6f-44aa-fa0a-cdaf39d33d3a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdullah</th>\n",
       "      <th>abone</th>\n",
       "      <th>about</th>\n",
       "      <th>acele</th>\n",
       "      <th>acil</th>\n",
       "      <th>activities</th>\n",
       "      <th>acı</th>\n",
       "      <th>ad</th>\n",
       "      <th>ada</th>\n",
       "      <th>adam</th>\n",
       "      <th>...</th>\n",
       "      <th>şubemiz</th>\n",
       "      <th>şubesi</th>\n",
       "      <th>şölen</th>\n",
       "      <th>şöleni</th>\n",
       "      <th>şöyle</th>\n",
       "      <th>şükranla</th>\n",
       "      <th>şükür</th>\n",
       "      <th>şık</th>\n",
       "      <th>şıklık</th>\n",
       "      <th>şıklığı</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abdullah  abone  about  acele  acil  activities  acı   ad  ada  adam  ...  \\\n",
       "0       0.0    0.0    0.0    0.0   0.0         0.0  0.0  0.0  0.0   0.0  ...   \n",
       "1       0.0    0.0    0.0    0.0   0.0         0.0  0.0  0.0  0.0   0.0  ...   \n",
       "\n",
       "   şubemiz  şubesi  şölen  şöleni  şöyle  şükranla  şükür       şık  şıklık  \\\n",
       "0      0.0     0.0    0.0     0.0    0.0       0.0    0.0  0.050596     0.0   \n",
       "1      0.0     0.0    0.0     0.0    0.0       0.0    0.0  0.000000     0.0   \n",
       "\n",
       "   şıklığı  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "\n",
       "[2 rows x 5000 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame(x_post_train.toarray(), columns=feature_names)\n",
    "df_tfidf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1i9xO_ZX1NXC",
    "outputId": "15c76222-630d-4c3c-9ba5-96a44af78a9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2741, 5000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "ehUT3JSFz7yo"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(df_tfidf, y_train, test_size=0.2, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipJX5GBZ1efb",
    "outputId": "dde21a01-9349-44de-cc16-3605f332f756"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2192, 5000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcjAvDsR-RyU",
    "outputId": "702f60e4-48e3-49ad-d883-0d4f417d695b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 5000)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Khu0eryhNZNN"
   },
   "source": [
    "# Naive Base Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "rdHIvFrSCMZj",
    "outputId": "043e1aaf-0e8b-4b20-8a32-c27298d253ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.01, 'class_prior': None, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#model = MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
    "#model.fit(x_train, y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0, 2.0, 10.0],  \n",
    "    'fit_prior': [True, False],  \n",
    "    'class_prior': [\n",
    "        None,  \n",
    "        [0.1] * 10,  \n",
    "        [0.3] + [0.1] * 9,  \n",
    "        [0.25] * 10  \n",
    "    ],\n",
    "}\n",
    "\n",
    "model = MultinomialNB()\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9ufQQ6TEX0Q",
    "outputId": "b3152a10-d637-4d03-fb87-ae1835dcc26a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8531021897810219\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "                 art       0.91      0.76      0.83       153\n",
      "       entertainment       0.82      0.79      0.80       258\n",
      "             fashion       0.82      0.90      0.86       239\n",
      "                food       0.94      0.90      0.92       409\n",
      "              gaming       1.00      1.00      1.00        10\n",
      "health and lifestyle       0.82      0.83      0.83       402\n",
      "    mom and children       0.90      0.85      0.87       119\n",
      "              sports       0.96      0.91      0.94        90\n",
      "                tech       0.83      0.91      0.87       277\n",
      "              travel       0.77      0.81      0.79       235\n",
      "\n",
      "            accuracy                           0.85      2192\n",
      "           macro avg       0.88      0.87      0.87      2192\n",
      "        weighted avg       0.86      0.85      0.85      2192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Train Data\n",
    "\n",
    "model = MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
    "model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_train, y_train_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyY9aFtGDrAj",
    "outputId": "e44c466d-6bf0-4556-ad4b-7c7111ad2835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6284153005464481\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "                 art       0.38      0.16      0.22        38\n",
      "       entertainment       0.42      0.51      0.46        65\n",
      "             fashion       0.58      0.72      0.64        60\n",
      "                food       0.79      0.86      0.82       102\n",
      "              gaming       0.00      0.00      0.00         3\n",
      "health and lifestyle       0.62      0.66      0.64       100\n",
      "    mom and children       0.78      0.23      0.36        30\n",
      "              sports       0.83      0.43      0.57        23\n",
      "                tech       0.72      0.81      0.76        69\n",
      "              travel       0.58      0.61      0.60        59\n",
      "\n",
      "            accuracy                           0.63       549\n",
      "           macro avg       0.57      0.50      0.51       549\n",
      "        weighted avg       0.63      0.63      0.61       549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Validation Data\n",
    "y_val_pred = model.predict(x_val)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AU6aALFaCMkd",
    "outputId": "83913a4f-45bc-4e1a-e069-06d452f31255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "livapastanesi\n",
      "barisgross\n",
      "tusasshop\n",
      "etolyadigital\n",
      "tugrulonur\n",
      "*****\n",
      "['livapastanesi', 'barisgross', 'tusasshop', 'etolyadigital', 'tugrulonur']\n"
     ]
    }
   ],
   "source": [
    "#@title Test Data\n",
    "\n",
    "\n",
    "# let's take a look at the first 5 lines of the file\n",
    "test_data_path = \"test-classification-round3.dat\"\n",
    "!head -n 5 \"$test_data_path\"\n",
    "\n",
    "print(\"*****\")\n",
    "\n",
    "test_unames = []\n",
    "with open(test_data_path, \"rt\") as fh:\n",
    "  for line in fh:\n",
    "    test_unames.append(line.strip())\n",
    "\n",
    "print(test_unames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqLF4LN8GqKm",
    "outputId": "779e32d6-a7be-4a03-d6c9-7f601b68cdbb"
   },
   "outputs": [],
   "source": [
    "x_test = []\n",
    "\n",
    "for uname in test_unames:\n",
    "  try:\n",
    "    index = test_usernames.index(uname)\n",
    "    x_test.append(x_post_test[index].toarray()[0])\n",
    "  except Exception as e:\n",
    "    try:\n",
    "      index = train_usernames.index(uname)\n",
    "      x_test.append(x_post_train[index].toarray()[0])\n",
    "    except Exception as e:\n",
    "      print(uname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "c2rswpw7IqGc",
    "outputId": "f6616829-1caa-41a2-c65f-72d82f4539c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdullah</th>\n",
       "      <th>abone</th>\n",
       "      <th>about</th>\n",
       "      <th>acele</th>\n",
       "      <th>acil</th>\n",
       "      <th>activities</th>\n",
       "      <th>acı</th>\n",
       "      <th>ad</th>\n",
       "      <th>ada</th>\n",
       "      <th>adam</th>\n",
       "      <th>...</th>\n",
       "      <th>şubemiz</th>\n",
       "      <th>şubesi</th>\n",
       "      <th>şölen</th>\n",
       "      <th>şöleni</th>\n",
       "      <th>şöyle</th>\n",
       "      <th>şükranla</th>\n",
       "      <th>şükür</th>\n",
       "      <th>şık</th>\n",
       "      <th>şıklık</th>\n",
       "      <th>şıklığı</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abdullah  abone  about  acele  acil  activities  acı   ad  ada  adam  ...  \\\n",
       "0       0.0    0.0    0.0    0.0   0.0         0.0  0.0  0.0  0.0   0.0  ...   \n",
       "1       0.0    0.0    0.0    0.0   0.0         0.0  0.0  0.0  0.0   0.0  ...   \n",
       "\n",
       "   şubemiz  şubesi  şölen  şöleni     şöyle  şükranla  şükür  şık  şıklık  \\\n",
       "0      0.0     0.0    0.0     0.0  0.038429       0.0    0.0  0.0     0.0   \n",
       "1      0.0     0.0    0.0     0.0  0.000000       0.0    0.0  0.0     0.0   \n",
       "\n",
       "   şıklığı  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "\n",
       "[2 rows x 5000 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(np.array(x_test), columns=feature_names)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "gUsUQtpMKTse"
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(df_test)\n",
    "\n",
    "output = dict()\n",
    "for index, uname in enumerate(test_unames):\n",
    "  output[uname] = test_pred[index]\n",
    "\n",
    "def capitalize_title(category):\n",
    "    # the words need to be not capital\n",
    "    exceptions = {\"and\"}\n",
    "    words = category.split()\n",
    "  \n",
    "    capitalized_words = [\n",
    "        word.capitalize() if word.lower() not in exceptions else word.lower()\n",
    "        for word in words\n",
    "    ]\n",
    "    return \" \".join(capitalized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "W-NJSnyxIrw4"
   },
   "outputs": [],
   "source": [
    "output = {uname: capitalize_title(category) for uname, category in output.items()}\n",
    "\n",
    "with open(\"output.json\", \"w\") as of:\n",
    "  json.dump(output, of, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHCv739JK6i8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDox_DtbFTpr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GpbmzCMFTsn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBLylyVoFTvf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xC7KXsQZL7Kp"
   },
   "source": [
    "# Like Count Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "nolpagasSuBq"
   },
   "outputs": [],
   "source": [
    "HYPERPARAMS = {\n",
    "    \"regularization\": 0.1,  # Regularization factor to adjust the average\n",
    "    \"time_decay\": 0.05    # Decay factor for timestamp weighting\n",
    "}\n",
    "\n",
    "def predict_like_count(username, current_post=None):\n",
    "\n",
    "    def get_avg_like_count(posts:list):\n",
    "        total = 0.\n",
    "        total_weight = 0.0\n",
    "        \n",
    "        for post in posts:\n",
    "            if current_post is not None and post[\"id\"] == current_post[\"id\"]:\n",
    "                continue\n",
    "\n",
    "            like_count = post.get(\"like_count\", 0)\n",
    "            if like_count is None:\n",
    "                like_count = 0\n",
    "\n",
    "            timestamp = post.get(\"timestamp\", None)\n",
    "            if timestamp:\n",
    "                post_date = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "                days_since_post = (datetime.now() - post_date).days\n",
    "                weight = 1 / (1 + HYPERPARAMS[\"time_decay\"] * days_since_post)\n",
    "            else:\n",
    "                weight = 1.0\n",
    "\n",
    "            weight = weight / len(posts)\n",
    "\n",
    "            total += like_count * weight\n",
    "            total_weight += weight\n",
    "        \n",
    "        if len(posts) == 0:\n",
    "            return 0.\n",
    "\n",
    "        if total_weight == 0:\n",
    "            return 0.0\n",
    "        if username in username2posts_train:\n",
    "            follower_count = train_profile_df[train_profile_df['username'] == username]['follower_count'].values[0]\n",
    "        else:\n",
    "            follower_count = test_profile_df[test_profile_df['username'] == username]['follower_count'].values[0]\n",
    "   \n",
    "\n",
    "    \n",
    "        if total / follower_count < 0.2:\n",
    "            user_regularization = HYPERPARAMS[\"regularization\"] * 2\n",
    "            return (total / total_weight) * (1 - user_regularization)\n",
    "        return (total / total_weight) * (1 - HYPERPARAMS[\"regularization\"])\n",
    "    \n",
    "\n",
    "    if username in username2posts_train:\n",
    "        return get_avg_like_count(username2posts_train[username])\n",
    "    elif username in username2posts_test:\n",
    "        return get_avg_like_count(username2posts_test[username])\n",
    "    else:\n",
    "        print(f\"No data available for {username}\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "ZNWTjLZ6XAuj"
   },
   "outputs": [],
   "source": [
    "def log_mse_like_counts(y_true, y_pred):\n",
    "\n",
    "  \n",
    "  y_true = np.array(y_true)\n",
    "  y_pred = np.array(y_pred)\n",
    "\n",
    "  \n",
    "  log_y_true = np.log1p(y_true)\n",
    "  log_y_pred = np.log1p(y_pred)\n",
    "\n",
    "  \n",
    "  squared_errors = (log_y_true - log_y_pred) ** 2\n",
    "\n",
    "  \n",
    "  return np.mean(squared_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1jETdAuXA0H",
    "outputId": "871164d0-74fb-49cd-ea77-b8a3e0793e81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log MSE Train= 1.1401158884334879\n"
     ]
    }
   ],
   "source": [
    "#@title Train Dataset evaluation\n",
    "\n",
    "y_like_count_train_true = []\n",
    "y_like_count_train_pred = []\n",
    "for uname, posts in username2posts_train.items():\n",
    "  for post in posts:\n",
    "    pred_val = predict_like_count(uname, post)\n",
    "    true_val = post.get(\"like_count\", 0)\n",
    "    if true_val is None:\n",
    "      true_val = 0\n",
    "\n",
    "    y_like_count_train_true.append(true_val)\n",
    "    y_like_count_train_pred.append(pred_val)\n",
    "\n",
    "print(f\"Log MSE Train= {log_mse_like_counts(y_like_count_train_true, y_like_count_train_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "F02V1wO-WBMV"
   },
   "outputs": [],
   "source": [
    "#@title Test Dataset\n",
    "\n",
    "path = \"test-regression-round3.jsonl\"\n",
    "\n",
    "to_predict_like_counts_usernames = []\n",
    "output_list = []\n",
    "dic = {}\n",
    "a = 0\n",
    "with open(path, \"rt\") as fh:\n",
    "    for line in fh:\n",
    "        sample = json.loads(line)\n",
    "        \n",
    "        pred_val = predict_like_count(sample[\"username\"])\n",
    "        sample[\"like_count\"] = int(pred_val)\n",
    "        dic[sample[\"id\"]] = sample[\"like_count\"]\n",
    "    \n",
    "with open(\"prediction-regression-round\", \"wt\") as of:\n",
    "    for key, value in dic.items():\n",
    "        of.write(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"prediction-regression-round\"    \n",
    "\n",
    "data = {}\n",
    "\n",
    "\n",
    "with open(input_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip() \n",
    "        if line:\n",
    "            key, value = line.split(\":\") \n",
    "            key = key.strip() \n",
    "            value = int(value.strip())\n",
    "            data[key] = value \n",
    "\n",
    "\n",
    "with open(\"prediction-regression-round3.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
